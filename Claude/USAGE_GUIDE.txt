"""
========================================
å®Œæ•´æ“ä½œæŒ‡å— - æœ¬åœ°éƒ¨ç½²ä¿®æ”¹
Complete Operation Guide - Local Deployment
========================================

ä½œè€…: Claude (åŸºäºç”¨æˆ·éœ€æ±‚)
æ—¥æœŸ: 2025-12-06
ç‰ˆæœ¬: 2.0 - å†å²æ•°æ®é©±åŠ¨WarmStart

æœ¬æŒ‡å—è¯¦ç»†è¯´æ˜å¦‚ä½•åœ¨æœ¬åœ°ä»£ç åº“ä¸­åº”ç”¨ä¿®æ”¹ã€‚
"""

# ============================================================================
# ğŸ“‹ ä¿®æ”¹æ¦‚è§ˆ
# ============================================================================

"""
æœ¬æ¬¡ä¿®æ”¹è§£å†³çš„é—®é¢˜:

âœ… é—®é¢˜1: WarmStartçš„promptæ˜¯ç¡¬ç¼–ç çš„
   â†’ è§£å†³: åˆ›å»ºBatteryKnowledgePromptGenerator,åŸºäºé¢†åŸŸçŸ¥è¯†åŠ¨æ€ç”Ÿæˆé«˜è´¨é‡prompt

âœ… é—®é¢˜2: Resultåªä¿å­˜æœ€ä¼˜è§£,æ ¼å¼ä¸å®Œæ•´
   â†’ è§£å†³: åˆ›å»ºResultManager,ä¿å­˜å®Œæ•´çš„è¯„ä¼°æ•°æ®åº“å’Œè¯¦ç»†ç»Ÿè®¡

âœ… é—®é¢˜3: WarmStartæ— æ³•åˆ©ç”¨å†å²æ•°æ®
   â†’ è§£å†³: åˆ›å»ºHistoricalWarmStart,è‡ªåŠ¨ä»å†å²Resultä¸­å­¦ä¹ æœ€ä¼˜/æœ€å·®/éšæœºè§£

âœ… é—®é¢˜4: ç¼ºä¹é«˜è´¨é‡çš„ç”µåŒ–å­¦é¢†åŸŸçŸ¥è¯†
   â†’ è§£å†³: åŸºäºæœ€æ–°å­¦æœ¯ç ”ç©¶æ•´åˆSEIç”Ÿé•¿ã€é”‚æå‡ºã€çƒ­ç®¡ç†ç­‰ç‰©ç†çº¦æŸ
"""

# ============================================================================
# ğŸ“ æ–‡ä»¶ç»“æ„
# ============================================================================

"""
ä½ éœ€è¦æ·»åŠ çš„æ–°æ–‡ä»¶:

BO/
â”œâ”€â”€ llmbo_core/
â”‚   â”œâ”€â”€ prompt_generator.py           â† æ–°å¢ (åŠ¨æ€Promptç”Ÿæˆå™¨)
â”‚   â”œâ”€â”€ result_manager.py             â† æ–°å¢ (Resultæ•°æ®ç®¡ç†)
â”‚   â”œâ”€â”€ historical_warmstart.py       â† æ–°å¢ (å†å²æ•°æ®é©±åŠ¨WarmStart)
â”‚   â””â”€â”€ multi_objective_evaluator.py  â† ä¿®æ”¹ (é›†æˆæ–°WarmStart)
â”‚
â”œâ”€â”€ LLM_Enhanced_Multi-Objective_Bayesian_Optimization.py  â† ä¿®æ”¹ (é›†æˆResultManager)
â”‚
â””â”€â”€ results/                          â† å·²å­˜åœ¨ (ä¿å­˜ç›®å½•,æ ¼å¼æ”¹è¿›)

æ€»å…±: 3ä¸ªæ–°æ–‡ä»¶ + 2ä¸ªä¿®æ”¹
"""

# ============================================================================
# ğŸš€ æ­¥éª¤1: å¤åˆ¶æ–°æ–‡ä»¶åˆ°æœ¬åœ°é¡¹ç›®
# ============================================================================

"""
1.1 ä¸‹è½½Claudeç”Ÿæˆçš„æ–‡ä»¶:
    - prompt_generator.py
    - result_manager.py  
    - historical_warmstart.py

1.2 æ”¾ç½®ä½ç½®:
    å°†ä»¥ä¸Š3ä¸ªæ–‡ä»¶å¤åˆ¶åˆ°ä½ çš„é¡¹ç›®çš„ llmbo_core/ ç›®å½•ä¸‹
    
    ä¾‹å¦‚:
    /your/project/path/BO/llmbo_core/prompt_generator.py
    /your/project/path/BO/llmbo_core/result_manager.py
    /your/project/path/BO/llmbo_core/historical_warmstart.py

1.3 éªŒè¯:
    cd /your/project/path/BO/llmbo_core/
    ls -l prompt_generator.py result_manager.py historical_warmstart.py
    
    åº”è¯¥çœ‹åˆ°3ä¸ªæ–‡ä»¶éƒ½å­˜åœ¨
"""

# ============================================================================
# ğŸ”§ æ­¥éª¤2: ä¿®æ”¹ multi_objective_evaluator.py
# ============================================================================

"""
2.1 æ‰“å¼€æ–‡ä»¶:
    vim llmbo_core/multi_objective_evaluator.py
    # æˆ–ä½¿ç”¨ä½ å–œæ¬¢çš„ç¼–è¾‘å™¨

2.2 åœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ å¯¼å…¥ (å¤§çº¦ç¬¬10-20è¡Œ):

    # ====== åŸæœ‰å¯¼å…¥ ======
    import numpy as np
    import asyncio
    from typing import Dict, List, Optional
    # ... å…¶ä»–å¯¼å…¥ ...
    
    # ====== æ–°å¢å¯¼å…¥ ======
    from historical_warmstart import HistoricalWarmStart  # æ–°å¢è¿™ä¸€è¡Œ

2.3 æ‰¾åˆ° initialize_with_llm_warmstart æ–¹æ³• (å¤§çº¦ç¬¬300è¡Œå·¦å³)
    æœç´¢: def initialize_with_llm_warmstart

2.4 æ›¿æ¢æ•´ä¸ªæ–¹æ³•ä½“:

    async def initialize_with_llm_warmstart(
        self,
        n_strategies: int = 5,
        llm_api_key: Optional[str] = None,
        llm_base_url: str = 'https://api.nuwaapi.com/v1',
        llm_model: str = "gpt-3.5-turbo"
    ) -> List[Dict]:
        \"\"\"
        ä½¿ç”¨ LLM è¿›è¡Œçƒ­å¯åŠ¨åˆå§‹åŒ– - æ–°ç‰ˆæœ¬ (å†å²æ•°æ®é©±åŠ¨)
        \"\"\"
        
        if self.verbose:
            print("\n" + "=" * 70)
            print("å¼€å§‹ LLM Warm Start åˆå§‹åŒ– (å†å²æ•°æ®é©±åŠ¨ç‰ˆ)")
            print("=" * 70)
            print(f"ç›®æ ‡ç­–ç•¥æ•°é‡: {n_strategies}")
            print(f"API Key: {'å·²æä¾›' if llm_api_key else 'æœªæä¾›ï¼ˆå°†ä½¿ç”¨éšæœºç­–ç•¥ï¼‰'}")
            print("=" * 70)
        
        results = []
        
        # ====== ä½¿ç”¨æ–°çš„HistoricalWarmStart ======
        if llm_api_key is not None:
            try:
                if self.verbose:
                    print("\nä½¿ç”¨HistoricalWarmStartç”Ÿæˆç­–ç•¥...")
                
                # åˆ›å»ºHistoricalWarmStartå®ä¾‹
                warmstart_generator = HistoricalWarmStart(
                    result_dir='./results',
                    llm_api_key=llm_api_key,
                    llm_base_url=llm_base_url,
                    llm_model=llm_model,
                    verbose=self.verbose
                )
                
                # ç”Ÿæˆç­–ç•¥
                strategies = await warmstart_generator.generate_warmstart_strategies_async(
                    n_strategies=n_strategies,
                    n_historical_runs=5,
                    objective_weights=self.weights,
                    exploration_mode='balanced'
                )
                
                if self.verbose:
                    print(f"[OK] HistoricalWarmStartæˆåŠŸç”Ÿæˆ {len(strategies)} ä¸ªç­–ç•¥")
                
            except Exception as e:
                if self.verbose:
                    print(f"âš ï¸  HistoricalWarmStartå¤±è´¥: {e}")
                    print("   å›é€€åˆ°éšæœºç­–ç•¥ç”Ÿæˆ...")
                
                strategies = self._generate_random_strategies(n_strategies)
        else:
            if self.verbose:
                print("\nä½¿ç”¨éšæœºç­–ç•¥ç”Ÿæˆ...")
            
            strategies = self._generate_random_strategies(n_strategies)
        
        # ====== è¯„ä¼°æ‰€æœ‰ç­–ç•¥ (ä¿æŒåŸæœ‰é€»è¾‘) ======
        if self.verbose:
            print(f"\nå¼€å§‹è¯„ä¼° {len(strategies)} ä¸ªç­–ç•¥...")
        
        for i, strategy in enumerate(strategies, 1):
            params = strategy['params']
            
            try:
                scalarized = self.evaluate(
                    current1=params['current1'],
                    charging_number=params['charging_number'],
                    current2=params['current2']
                )
                
                latest_log = self.detailed_logs[-1]
                
                result = {
                    'params': params,
                    'scalarized': scalarized,
                    'objectives': latest_log['objectives'],
                    'valid': latest_log['valid'],
                    'source': strategy.get('source', 'llm_warmstart'),
                    'reasoning': strategy.get('reasoning', '')
                }
                
                results.append(result)
                
                if self.verbose:
                    print(f"  ç­–ç•¥ {i}/{len(strategies)}: "
                          f"I1={params['current1']:.2f}A, "
                          f"t1={params['charging_number']}, "
                          f"I2={params['current2']:.2f}A "
                          f"â†’ æ ‡é‡åŒ–={scalarized:.4f}")
            
            except Exception as e:
                if self.verbose:
                    print(f"  âœ— ç­–ç•¥ {i} è¯„ä¼°å¤±è´¥: {e}")
                continue
        
        if self.verbose:
            print(f"\n[OK] Warm Startå®Œæˆ! æˆåŠŸè¯„ä¼° {len(results)}/{len(strategies)} ä¸ªç­–ç•¥")
            print("=" * 70)
        
        return results

2.5 åˆ é™¤æˆ–æ³¨é‡Šæ‰åŸæœ‰çš„ _llm_generate_strategies æ–¹æ³•:

    æœç´¢: async def _llm_generate_strategies
    
    å°†æ•´ä¸ªæ–¹æ³•æ³¨é‡Šæ‰æˆ–åˆ é™¤:
    
    # âŒ åˆ é™¤è¿™ä¸ªæ–¹æ³• (ç¡¬ç¼–ç prompt)
    # async def _llm_generate_strategies(
    #     self,
    #     n_strategies: int,
    #     api_key: str,
    #     base_url: str,
    #     model: str
    # ) -> List[Dict]:
    #     ...åŸæœ‰ä»£ç ...

2.6 ä¿å­˜æ–‡ä»¶:
    :wq (vim)
    æˆ– Ctrl+S (å…¶ä»–ç¼–è¾‘å™¨)
"""

# ============================================================================
# ğŸ”§ æ­¥éª¤3: ä¿®æ”¹ä¸»ä¼˜åŒ–å™¨æ–‡ä»¶
# ============================================================================

"""
3.1 æ‰“å¼€æ–‡ä»¶:
    vim LLM_Enhanced_Multi-Objective_Bayesian_Optimization.py

3.2 åœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ å¯¼å…¥ (å¤§çº¦ç¬¬50-60è¡Œ):

    # ====== åŸæœ‰å¯¼å…¥ ======
    from multi_objective_evaluator import MultiObjectiveEvaluator
    from LLM_enhanced_surrogate_modeling import LLMEnhancedBO
    from LLM_Enhanced_Expected_Improvement import LLMEnhancedEI
    
    # ====== æ–°å¢å¯¼å…¥ ======
    from result_manager import ResultManager  # æ–°å¢è¿™ä¸€è¡Œ

3.3 åœ¨ __init__ æ–¹æ³•ä¸­åˆå§‹åŒ–ResultManager (å¤§çº¦ç¬¬100è¡Œ):

    def __init__(
        self,
        llm_api_key: str,
        ...
        save_dir: str = './results'
    ):
        # ... åŸæœ‰ä»£ç  ...
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        os.makedirs(save_dir, exist_ok=True)
        
        # ====== æ–°å¢: åˆå§‹åŒ–ResultManager ======
        self.result_manager = ResultManager(save_dir=save_dir)  # æ–°å¢è¿™ä¸€è¡Œ
        
        # ä¼˜åŒ–å†å²
        self.optimization_history = []
        
        # ... å…¶ä½™ä»£ç ä¿æŒä¸å˜ ...

3.4 ä¿®æ”¹ export_results æ–¹æ³• (å¤§çº¦ç¬¬400-450è¡Œ):

    def export_results(self, filename: str = None) -> str:
        \"\"\"
        å¯¼å‡ºç»“æœåˆ°JSONæ–‡ä»¶ - ä½¿ç”¨ResultManagerä¿å­˜å®Œæ•´æ•°æ®
        \"\"\"
        
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            run_id = f"llm_mobo_{timestamp}"
        else:
            run_id = filename.replace('.json', '')
        
        # è·å–å®Œæ•´æ•°æ®
        database = self.evaluator.export_database()
        best_solution = self.evaluator.get_best_solution()
        pareto_front = self.evaluator.get_pareto_front()
        statistics = self.evaluator.get_statistics()
        
        # é…ç½®ä¿¡æ¯
        config = {
            'llm_model': self.llm_model,
            'n_warmstart': self.n_warmstart,
            'n_random_init': self.n_random_init,
            'n_iterations': self.n_iterations,
            'objective_weights': self.evaluator.weights,
            'enable_llm_warmstart': self.enable_llm_warmstart,
            'enable_llm_surrogate': self.enable_llm_surrogate,
            'enable_llm_ei': self.enable_llm_ei
        }
        
        # ====== ä½¿ç”¨ResultManagerä¿å­˜ ======
        filepath = self.result_manager.save_optimization_run(
            run_id=run_id,
            database=database,
            best_solution=best_solution,
            pareto_front=pareto_front,
            config=config,
            statistics=statistics,
            metadata={
                'elapsed_time': self.optimization_history[-1].get('elapsed_time', 0) if self.optimization_history else 0
            }
        )
        
        print(f"\nâœ“ å®Œæ•´ä¼˜åŒ–ç»“æœå·²ä¿å­˜")
        return filepath

3.5 ä¿å­˜æ–‡ä»¶
"""

# ============================================================================
# âœ… æ­¥éª¤4: éªŒè¯ä¿®æ”¹
# ============================================================================

"""
4.1 æµ‹è¯•æ–°æ¨¡å—æ˜¯å¦èƒ½å¯¼å…¥:

    cd /your/project/path/BO/llmbo_core/
    python3 -c "from prompt_generator import BatteryKnowledgePromptGenerator; print('âœ“ prompt_generatorå¯¼å…¥æˆåŠŸ')"
    python3 -c "from result_manager import ResultManager; print('âœ“ result_managerå¯¼å…¥æˆåŠŸ')"
    python3 -c "from historical_warmstart import HistoricalWarmStart; print('âœ“ historical_warmstartå¯¼å…¥æˆåŠŸ')"

4.2 æµ‹è¯•ç‹¬ç«‹åŠŸèƒ½:

    # æµ‹è¯•Promptç”Ÿæˆå™¨
    python3 prompt_generator.py
    
    # æµ‹è¯•Resultç®¡ç†å™¨
    python3 result_manager.py
    
    # æµ‹è¯•HistoricalWarmStart
    python3 historical_warmstart.py

4.3 æ£€æŸ¥è¯­æ³•é”™è¯¯:

    python3 -m py_compile multi_objective_evaluator.py
    python3 -m py_compile LLM_Enhanced_Multi-Objective_Bayesian_Optimization.py

    å¦‚æœæ²¡æœ‰è¾“å‡º,è¯´æ˜è¯­æ³•æ­£ç¡®
"""

# ============================================================================
# ğŸš€ æ­¥éª¤5: è¿è¡Œä¼˜åŒ–æµ‹è¯•
# ============================================================================

"""
5.1 åˆ›å»ºæµ‹è¯•è„šæœ¬ test_new_warmstart.py:

    import asyncio
    from LLM_Enhanced_Multi_Objective_Bayesian_Optimization import LLMEnhancedMultiObjectiveBO
    
    async def test():
        # åˆ›å»ºä¼˜åŒ–å™¨
        optimizer = LLMEnhancedMultiObjectiveBO(
            llm_api_key='your-api-key-here',  # æ›¿æ¢ä¸ºçœŸå®API key
            llm_base_url='https://api.nuwaapi.com/v1',
            llm_model='gpt-3.5-turbo',
            n_warmstart=5,
            n_iterations=10,  # æµ‹è¯•ç”¨å°‘é‡è¿­ä»£
            n_random_init=3,
            enable_llm_warmstart=True,
            verbose=True,
            save_dir='./results'
        )
        
        # è¿è¡Œä¼˜åŒ–
        results = await optimizer.optimize_async()
        
        # å¯¼å‡ºç»“æœ
        optimizer.export_results()
        
        print("\nâœ“ æµ‹è¯•å®Œæˆ!")
    
    if __name__ == "__main__":
        asyncio.run(test())

5.2 è¿è¡Œæµ‹è¯•:

    python3 test_new_warmstart.py

5.3 æ£€æŸ¥è¾“å‡º:

    åº”è¯¥çœ‹åˆ°:
    - [HistoricalWarmStart] åˆå§‹åŒ–å®Œæˆ
    - åŠ è½½å†å²æ•°æ® (å¦‚æœæœ‰çš„è¯)
    - ç”Ÿæˆé«˜è´¨é‡prompt
    - LLMç”Ÿæˆç­–ç•¥
    - è¯„ä¼°ç­–ç•¥
    - ä¿å­˜å®Œæ•´ç»“æœåˆ° results/ ç›®å½•

5.4 éªŒè¯ä¿å­˜çš„ç»“æœæ–‡ä»¶:

    cat results/llm_mobo_YYYYMMDD_HHMMSS.json | head -n 50
    
    åº”è¯¥çœ‹åˆ°å®Œæ•´çš„JSONç»“æ„,åŒ…æ‹¬:
    - run_id
    - timestamp
    - config
    - statistics
    - best_solution
    - pareto_front
    - database (æ‰€æœ‰è¯„ä¼°ç‚¹!)  â† å…³é”®!
    - analysis
"""

# ============================================================================
# ğŸ“Š æ­¥éª¤6: éªŒè¯å†å²æ•°æ®åŠŸèƒ½
# ============================================================================

"""
6.1 è¿è¡Œç¬¬äºŒæ¬¡ä¼˜åŒ–:

    ç¬¬äºŒæ¬¡è¿è¡Œæ—¶,HistoricalWarmStartä¼šè‡ªåŠ¨:
    - åŠ è½½ç¬¬ä¸€æ¬¡è¿è¡Œçš„ç»“æœ
    - æå–æœ€ä¼˜10ä¸ªã€æœ€å·®10ä¸ªè§£
    - åœ¨promptä¸­æä¾›few-shot examples
    - ç”Ÿæˆæ”¹è¿›çš„ç­–ç•¥

6.2 æŸ¥çœ‹promptå†…å®¹ (è°ƒè¯•ç”¨):

    åœ¨ historical_warmstart.py çš„ _call_llm_async æ–¹æ³•ä¸­æ·»åŠ :
    
    print("\nç”Ÿæˆçš„Prompt:")
    print("=" * 80)
    print(prompt)
    print("=" * 80)

6.3 æ¯”è¾ƒä¸¤æ¬¡è¿è¡Œçš„ç»“æœ:

    ç¬¬ä¸€æ¬¡: çº¯é¢†åŸŸçŸ¥è¯† + éšæœºæ¢ç´¢
    ç¬¬äºŒæ¬¡: é¢†åŸŸçŸ¥è¯† + å†å²æœ€ä¼˜è§£å¼•å¯¼

    ç¬¬äºŒæ¬¡åº”è¯¥æ”¶æ•›æ›´å¿«!
"""

# ============================================================================
# ğŸ¯ æ­¥éª¤7: é«˜çº§é…ç½® (å¯é€‰)
# ============================================================================

"""
7.1 è°ƒæ•´æ¢ç´¢æ¨¡å¼:

    åœ¨è°ƒç”¨æ—¶è®¾ç½®exploration_mode:
    
    - 'conservative': ä¿å®ˆ,é è¿‘å·²çŸ¥å¥½è§£
    - 'balanced': å¹³è¡¡,æ··åˆå·²çŸ¥å’Œæ¢ç´¢ (é»˜è®¤)
    - 'aggressive': æ¿€è¿›,æ¢ç´¢è¾¹ç•ŒåŒºåŸŸ

    warmstart_generator.generate_warmstart_strategies_async(
        n_strategies=5,
        exploration_mode='aggressive'  # ä¿®æ”¹è¿™é‡Œ
    )

7.2 è°ƒæ•´å†å²æ•°æ®åŠ è½½é‡:

    n_historical_runs=10  # åŠ è½½æœ€è¿‘10æ¬¡è¿è¡Œ (é»˜è®¤5)

7.3 è°ƒæ•´Few-Shotæ ·ä¾‹æ•°é‡:

    åœ¨ prompt_generator.py çš„ generate_warmstart_prompt æ–¹æ³•ä¸­:
    
    historical_best=historical_best[:5]  # æ”¹ä¸º5ä¸ªæœ€ä¼˜è§£
    historical_worst=historical_worst[:3]  # æ”¹ä¸º3ä¸ªæœ€å·®è§£

7.4 è‡ªå®šä¹‰é¢†åŸŸçŸ¥è¯†:

    åœ¨ prompt_generator.py çš„ __init__ ä¸­ä¿®æ”¹ self.physics_knowledge
    æ·»åŠ ä½ è‡ªå·±çš„ç”µåŒ–å­¦è§è§£!
"""

# ============================================================================
# ğŸ› æ•…éšœæ’æŸ¥
# ============================================================================

"""
é—®é¢˜1: ImportError: No module named 'historical_warmstart'
è§£å†³: ç¡®ä¿æ–‡ä»¶æ”¾åœ¨æ­£ç¡®çš„ç›®å½•,å¹¶ä¸”ç›®å½•ä¸­æœ‰ __init__.py

é—®é¢˜2: LLMè¿”å›çš„ä¸æ˜¯æœ‰æ•ˆJSON
è§£å†³: æ£€æŸ¥LLMæ¨¡å‹æ˜¯å¦æ”¯æŒJSONæ ¼å¼,æˆ–åœ¨promptä¸­å¼ºè°ƒJSONæ ¼å¼

é—®é¢˜3: å†å²æ•°æ®åŠ è½½å¤±è´¥
è§£å†³: æ£€æŸ¥ results/ ç›®å½•æ˜¯å¦å­˜åœ¨,æ˜¯å¦æœ‰.jsonæ–‡ä»¶

é—®é¢˜4: ç­–ç•¥ç”Ÿæˆæ•°é‡ä¸è¶³
è§£å†³: LLMå¯èƒ½ç”Ÿæˆæ— æ•ˆç­–ç•¥,æ£€æŸ¥å‚æ•°éªŒè¯é€»è¾‘

é—®é¢˜5: è¯„ä¼°å¤±è´¥
è§£å†³: æ£€æŸ¥SPMæ¨¡å‹æ˜¯å¦æ­£å¸¸å·¥ä½œ,å‚æ•°æ˜¯å¦åœ¨æœ‰æ•ˆèŒƒå›´å†…
"""

# ============================================================================
# âœ… éªŒè¯æ¸…å•
# ============================================================================

"""
å®Œæˆåæ£€æŸ¥:

[ ] 3ä¸ªæ–°æ–‡ä»¶å·²å¤åˆ¶åˆ° llmbo_core/ ç›®å½•
[ ] multi_objective_evaluator.py å·²ä¿®æ”¹
    [ ] æ·»åŠ äº† HistoricalWarmStart å¯¼å…¥
    [ ] ä¿®æ”¹äº† initialize_with_llm_warmstart æ–¹æ³•
    [ ] åˆ é™¤äº† _llm_generate_strategies æ–¹æ³•
[ ] LLM_Enhanced_Multi-Objective_Bayesian_Optimization.py å·²ä¿®æ”¹
    [ ] æ·»åŠ äº† ResultManager å¯¼å…¥
    [ ] åˆå§‹åŒ–äº† self.result_manager
    [ ] ä¿®æ”¹äº† export_results æ–¹æ³•
[ ] æ‰€æœ‰æ¨¡å—å¯ä»¥æˆåŠŸå¯¼å…¥
[ ] æµ‹è¯•è¿è¡ŒæˆåŠŸ
[ ] ç»“æœæ–‡ä»¶åŒ…å«å®Œæ•´database
[ ] ç¬¬äºŒæ¬¡è¿è¡Œå¯ä»¥åŠ è½½å†å²æ•°æ®
[ ] PromptåŒ…å«few-shot examples

å…¨éƒ¨å‹¾é€‰ â†’ ä¿®æ”¹å®Œæˆ! ğŸ‰
"""

# ============================================================================
# ğŸ“š è¿›ä¸€æ­¥ä¼˜åŒ–å»ºè®®
# ============================================================================

"""
1. é›†æˆåˆ°Comparisonæ¡†æ¶:
   - ä¿®æ”¹ comparison_runner.py ä½¿ç”¨ ResultManager
   - æ¯”è¾ƒä¸åŒç®—æ³•æ—¶ä¹Ÿä¿å­˜å®Œæ•´database

2. å¯è§†åŒ–æ”¹è¿›:
   - ä½¿ç”¨ analysis å­—æ®µç”Ÿæˆæ›´è¯¦ç»†çš„å›¾è¡¨
   - å¯¹æ¯”å†å²è¿è¡Œçš„æ”¶æ•›æ›²çº¿

3. è‡ªåŠ¨è°ƒä¼˜:
   - æ ¹æ®å†å²æ€§èƒ½è‡ªåŠ¨è°ƒæ•´ exploration_mode
   - æ£€æµ‹åœæ»æ—¶åˆ‡æ¢åˆ° aggressive

4. å¢é‡å­¦ä¹ :
   - æ¯Næ¬¡è¿è¡Œæ›´æ–°prompt template
   - ä»å¤±è´¥ç­–ç•¥ä¸­å­¦ä¹ é¿å…åŒºåŸŸ

5. å¤šç›®æ ‡Paretoå­¦ä¹ :
   - ä¸ä»…å­¦ä¹ æ ‡é‡æœ€ä¼˜,è¿˜å­¦ä¹ Paretoå‰æ²¿
   - ç”Ÿæˆå¤šæ ·åŒ–çš„Paretoè§£

å‚è€ƒè®ºæ–‡ä¸­çš„æ–¹æ³•ç»§ç»­æ‰©å±•!
"""

# ============================================================================
# ğŸ“§ éœ€è¦å¸®åŠ©?
# ============================================================================

"""
å¦‚æœé‡åˆ°é—®é¢˜:

1. æ£€æŸ¥æœ¬æ–‡æ¡£çš„æ•…éšœæ’æŸ¥éƒ¨åˆ†
2. è¿è¡Œç‹¬ç«‹æµ‹è¯•è„šæœ¬éªŒè¯å„æ¨¡å—
3. æŸ¥çœ‹MODIFICATION_EXAMPLE.pyä¸­çš„ä»£ç ç¤ºä¾‹
4. å‚è€ƒè®ºæ–‡ manuscript1.pdf çš„ Figure 2-4

ç¥ä¼˜åŒ–é¡ºåˆ©! ğŸš€
"""
